---
title: "PA 6.2"
format:
  html:
    embed-resources: true
code-fold: true
---

# Palmer Penguins Modeling

Import the Palmer Penguins dataset and print out the first few rows.

Suppose we want to predict `bill_depth_mm` using the other variables in the dataset.

**Dummify** all variables that require this.


```{python}
pip install palmerpenguins
```


```{python}
from palmerpenguins import load_penguins
penguins = load_penguins()
penguins.head()
```


```{python}
import pandas as pd
penguins_dumb = pd.get_dummies(penguins, columns=['species', 'sex'])
penguins_dumb = penguins_dumb.dropna()
penguins_dumb.head()
```

Let's use the other variables to predict bill_depth_mm. Prepare your data and fit the following models on a training dataset subset of the entire dataset:

Four different models, each containing a different set of predictor variables
Create a plot like the right plot of Fig 1. in our Model Validation chapter with the training and test error plotted for each of your four models.

Which of your models was best?


```{python}
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(penguins_dumb.drop(['bill_depth_mm'], axis=1), penguins_dumb['bill_depth_mm'], test_size=0.25)
```


```{python}
X_train
```


```{python}
y_train
```


```{python}
X_test
```


```{python}
y_test
```


```{python}
from sklearn.metrics import root_mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression

depth_model = LinearRegression()

models = {
    "Model 1": ['bill_length_mm', 'flipper_length_mm'],
    "Model 2": ['bill_length_mm', 'flipper_length_mm', 'body_mass_g', 'year', 'sex_female', 'sex_male'],
    "Model 3": ['bill_length_mm', 'flipper_length_mm', 'body_mass_g', 'year', 'species_Adelie', 'species_Chinstrap', 'species_Gentoo'],
    "Model 4": ['bill_length_mm', 'flipper_length_mm', 'body_mass_g', 'year', 'species_Adelie', 'species_Chinstrap', 'species_Gentoo', 'sex_female', 'sex_male']
}

rows = []
for name, Xcols in models.items():
    X = X_train[Xcols]
    model = LinearRegression().fit(X, y_train)
    y_test_ = model.predict(X_test[Xcols])
    y_train_ = model.predict(X_train[Xcols])
    X_test[f"{name}_predict"] = y_test_
    test_rmse = root_mean_squared_error(y_test, y_test_)
    train_rmse = root_mean_squared_error(y_train, y_train_)  
    test_r2 = r2_score(y_test, y_test_)
    train_r2 = r2_score(y_train, y_train_)
    rows.append({"Model": name, "Test RMSE": test_rmse, "Train RMSE": train_rmse, "Test R2": test_r2, "Train R2": train_r2})

test_error = pd.DataFrame(rows)
test_error
```


```{python}
df_error = test_error.merge(test_error, on="Model")
df_error
```


```{python}
from plotnine import *

df_long = df_error.melt(id_vars='Model', value_vars=['Train RMSE_y', 'Test RMSE_y'],
                  var_name='Metric', value_name='RMSE')

(ggplot(df_long, aes(x='Model', y='RMSE', color='Metric', group='Metric'))
    + geom_line(size=1.2)
    + geom_point(size=3)
    + labs(title='Test RMSE Comparison Across Models',
           x='Model', y='RMSE')
)
```


```{python}
df_long = df_error.melt(id_vars='Model', value_vars=['Train R2_y', 'Test R2_y'],
                     var_name='Metric', value_name='R2')

(ggplot(df_long, aes(x='Model', y='R2', color='Metric', group='Metric'))
    + geom_line(size=1.2)
    + geom_point(size=3)
    + labs(title='Test R² Comparison Across Models',
           x='Model', y='R²')
    + theme_minimal()
    + scale_color_manual(values=['#2ca02c', '#d62728'])
)

```

Model 4 was the best, which incldued all the variables, this makes me suspect overfitting. 